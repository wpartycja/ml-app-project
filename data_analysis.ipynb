{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fee46a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e426d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/keywords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5b7bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"keywords_nan\"] = data[\"keywords\"].replace(\"[]\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cba5f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'id': 931, 'name': 'jealousy'}, {'id': 4290, 'name': 'toy'}, {'id': 5202, 'name': 'boy'}, {'id': 6054, 'name': 'friendship'}, {'id': 9713, 'name': 'friends'}, {'id': 9823, 'name': 'rivalry'}, {'id': 165503, 'name': 'boy next door'}, {'id': 170722, 'name': 'new toy'}, {'id': 187065, 'name': 'toy comes to life'}]\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[[0]].keywords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f014a315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_word_grabber(text):\n",
    "    \n",
    "    if text is not np.nan:\n",
    "        \n",
    "        return re.findall(r\"'name':\\s*'([^']*)'\", text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e37a22f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"keywords_list\"] = data[\"keywords_nan\"].apply(lambda x: key_word_grabber(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acabaca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14795"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"keywords_nan\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f43610f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46419, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a69ee485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [jealousy, toy, boy, friendship, friends, riva...\n",
       "1        [board game, disappearance, new home, recluse,...\n",
       "2        [fishing, best friend, duringcreditsstinger, o...\n",
       "3        [based on novel, interracial relationship, sin...\n",
       "4        [baby, midlife crisis, confidence, aging, daug...\n",
       "                               ...                        \n",
       "46414                                        [tragic love]\n",
       "46415                                [artist, play, pinoy]\n",
       "46416                                                  NaN\n",
       "46417                                                  NaN\n",
       "46418                                                  NaN\n",
       "Name: keywords_list, Length: 46419, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"keywords_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b407d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46419, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "382b2137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]                                                                                                                                                                                                                             14795\n",
       "[{'id': 187056, 'name': 'woman director'}]                                                                                                                                                                                      1323\n",
       "[{'id': 10183, 'name': 'independent film'}]                                                                                                                                                                                      509\n",
       "[{'id': 9716, 'name': 'stand-up comedy'}]                                                                                                                                                                                        235\n",
       "[{'id': 4344, 'name': 'musical'}]                                                                                                                                                                                                170\n",
       "                                                                                                                                                                                                                               ...  \n",
       "[{'id': 187310, 'name': 'springfield illinois'}, {'id': 207928, 'name': '19th century'}, {'id': 209409, 'name': 'abraham lincoln'}]                                                                                                1\n",
       "[{'id': 1299, 'name': 'monster'}, {'id': 1852, 'name': 'mutant'}, {'id': 9794, 'name': 'toxic'}, {'id': 10322, 'name': 'native american'}, {'id': 33480, 'name': 'environmental'}, {'id': 223059, 'name': 'animal horror'}]        1\n",
       "[{'id': 6946, 'name': 'blonde'}]                                                                                                                                                                                                   1\n",
       "[{'id': 110, 'name': 'venice'}, {'id': 703, 'name': 'detective'}, {'id': 1328, 'name': 'secret'}, {'id': 2041, 'name': 'island'}, {'id': 7063, 'name': 'children gang'}, {'id': 155790, 'name': 'private detective'}]              1\n",
       "[{'id': 2679, 'name': 'artist'}, {'id': 14531, 'name': 'play'}, {'id': 215397, 'name': 'pinoy'}]                                                                                                                                   1\n",
       "Name: keywords, Length: 25989, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"keywords\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8118abb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.iloc[46418][\"keywords_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb61c198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [jealousy, toy, boy, friendship, friends, riva...\n",
       "1        [board game, disappearance, new home, recluse,...\n",
       "2        [fishing, best friend, duringcreditsstinger, o...\n",
       "3        [based on novel, interracial relationship, sin...\n",
       "4        [baby, midlife crisis, confidence, aging, daug...\n",
       "                               ...                        \n",
       "46414                                        [tragic love]\n",
       "46415                                [artist, play, pinoy]\n",
       "46416                                                   []\n",
       "46417                                                   []\n",
       "46418                                                   []\n",
       "Name: keywords_list, Length: 46419, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"keywords_list\"].apply(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6d651777",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "data2 = pd.read_csv(\"data/movies_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af99ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop(data2.loc[data2['overview']==\"No overview found.\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7c75809",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop(data2.loc[data2['overview']==\"No Overview\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e08295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop(data2.loc[data2['overview']==\"\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92c3078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop(data2.loc[data2['overview']==\"No movie overview available\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a596566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_overview(text):\n",
    "    \n",
    "    if text is not np.nan:\n",
    "        \n",
    "        if len(text) < 20:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "076f409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[\"overview_filtered\"] = data2[\"overview\"].apply(lambda x: parse_overview(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ed13c5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2[data2[\"overview_filtered\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "59d53a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\"keywords_nan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5223806a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/34/1yvhb8vj085g3m5tpn1x91d80000gn/T/ipykernel_72364/862761141.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2[\"id\"]=data2[\"id\"].astype(int)\n"
     ]
    }
   ],
   "source": [
    "data2[\"id\"] = data2[\"id\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c124fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = data2.merge(data, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08427904",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>keywords_list</th>\n",
       "      <th>keywords_nan</th>\n",
       "      <th>tmpp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21818</th>\n",
       "      <td>91745</td>\n",
       "      <td>[{'id': 497, 'name': 'shakespeare'}, {'id': 13...</td>\n",
       "      <td>[shakespeare, teenager, middle ages, family fe...</td>\n",
       "      <td>[{'id': 497, 'name': 'shakespeare'}, {'id': 13...</td>\n",
       "      <td>Film by Risto Jarva.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20301</th>\n",
       "      <td>84328</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35326</th>\n",
       "      <td>351819</td>\n",
       "      <td>[{'id': 572, 'name': 'sex'}, {'id': 9215, 'nam...</td>\n",
       "      <td>[sex, black, parody, spoof, millionaire]</td>\n",
       "      <td>[{'id': 572, 'name': 'sex'}, {'id': 9215, 'nam...</td>\n",
       "      <td>Finnish documentary.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31468</th>\n",
       "      <td>87884</td>\n",
       "      <td>[{'id': 293, 'name': 'female nudity'}, {'id': ...</td>\n",
       "      <td>[female nudity, teacher]</td>\n",
       "      <td>[{'id': 293, 'name': 'female nudity'}, {'id': ...</td>\n",
       "      <td>Based on true events</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30334</th>\n",
       "      <td>13803</td>\n",
       "      <td>[{'id': 12663, 'name': 'little girl'}, {'id': ...</td>\n",
       "      <td>[little girl, killer]</td>\n",
       "      <td>[{'id': 12663, 'name': 'little girl'}, {'id': ...</td>\n",
       "      <td>For a Book of Dollars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34664</th>\n",
       "      <td>337751</td>\n",
       "      <td>[{'id': 9073, 'name': 'marilyn monroe'}, {'id'...</td>\n",
       "      <td>[marilyn monroe, woman director]</td>\n",
       "      <td>[{'id': 9073, 'name': 'marilyn monroe'}, {'id'...</td>\n",
       "      <td>Standup in Las Vegas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43368</th>\n",
       "      <td>435351</td>\n",
       "      <td>[{'id': 9716, 'name': 'stand-up comedy'}]</td>\n",
       "      <td>[stand-up comedy]</td>\n",
       "      <td>[{'id': 9716, 'name': 'stand-up comedy'}]</td>\n",
       "      <td>A journey into night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22078</th>\n",
       "      <td>15991</td>\n",
       "      <td>[{'id': 293, 'name': 'female nudity'}, {'id': ...</td>\n",
       "      <td>[female nudity, orgasm]</td>\n",
       "      <td>[{'id': 293, 'name': 'female nudity'}, {'id': ...</td>\n",
       "      <td>A film by Jari Halonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27491</th>\n",
       "      <td>171292</td>\n",
       "      <td>[{'id': 174878, 'name': 'female vampire'}]</td>\n",
       "      <td>[female vampire]</td>\n",
       "      <td>[{'id': 174878, 'name': 'female vampire'}]</td>\n",
       "      <td>A man dances on curbs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43931</th>\n",
       "      <td>255552</td>\n",
       "      <td>[{'id': 380, 'name': 'brother brother relation...</td>\n",
       "      <td>[brother brother relationship, family, missing...</td>\n",
       "      <td>[{'id': 380, 'name': 'brother brother relation...</td>\n",
       "      <td>Love on the front page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32513</th>\n",
       "      <td>270470</td>\n",
       "      <td>[{'id': 344, 'name': 'inquisition'}, {'id': 43...</td>\n",
       "      <td>[inquisition, painter, spain, artist, biography]</td>\n",
       "      <td>[{'id': 344, 'name': 'inquisition'}, {'id': 43...</td>\n",
       "      <td>Movie by Luciano Salce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13305</th>\n",
       "      <td>260528</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frisian movie from 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20760</th>\n",
       "      <td>85510</td>\n",
       "      <td>[{'id': 2106, 'name': 'cold war'}, {'id': 4210...</td>\n",
       "      <td>[cold war, panic, nuclear war]</td>\n",
       "      <td>[{'id': 2106, 'name': 'cold war'}, {'id': 4210...</td>\n",
       "      <td>Film by Veikko Aaltonen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>279698</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Film from Stephen Kijak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43086</th>\n",
       "      <td>424661</td>\n",
       "      <td>[{'id': 1530, 'name': 'temple'}, {'id': 10364,...</td>\n",
       "      <td>[temple, mission, jungle]</td>\n",
       "      <td>[{'id': 1530, 'name': 'temple'}, {'id': 10364,...</td>\n",
       "      <td>English gangster flick.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22180</th>\n",
       "      <td>54236</td>\n",
       "      <td>[{'id': 9935, 'name': 'travel'}, {'id': 155733...</td>\n",
       "      <td>[travel, old house, segovia]</td>\n",
       "      <td>[{'id': 9935, 'name': 'travel'}, {'id': 155733...</td>\n",
       "      <td>Short WW II documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31475</th>\n",
       "      <td>337879</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Directed by Vanessa Hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40187</th>\n",
       "      <td>377462</td>\n",
       "      <td>[{'id': 41385, 'name': 'racial tension'}, {'id...</td>\n",
       "      <td>[racial tension, american football player, mur...</td>\n",
       "      <td>[{'id': 41385, 'name': 'racial tension'}, {'id...</td>\n",
       "      <td>Fifth Break Blade Movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13313</th>\n",
       "      <td>125705</td>\n",
       "      <td>[{'id': 497, 'name': 'shakespeare'}]</td>\n",
       "      <td>[shakespeare]</td>\n",
       "      <td>[{'id': 497, 'name': 'shakespeare'}]</td>\n",
       "      <td>To be or not to be, etc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38682</th>\n",
       "      <td>356326</td>\n",
       "      <td>[{'id': 12377, 'name': 'zombie'}, {'id': 18895...</td>\n",
       "      <td>[zombie, virus]</td>\n",
       "      <td>[{'id': 12377, 'name': 'zombie'}, {'id': 18895...</td>\n",
       "      <td>Thrice upon a love story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35692</th>\n",
       "      <td>376358</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Directed by  Özcan Deniz.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40186</th>\n",
       "      <td>305309</td>\n",
       "      <td>[{'id': 187056, 'name': 'woman director'}]</td>\n",
       "      <td>[woman director]</td>\n",
       "      <td>[{'id': 187056, 'name': 'woman director'}]</td>\n",
       "      <td>Fourth Break Blade Movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39471</th>\n",
       "      <td>46740</td>\n",
       "      <td>[{'id': 161817, 'name': 'monty python'}]</td>\n",
       "      <td>[monty python]</td>\n",
       "      <td>[{'id': 161817, 'name': 'monty python'}]</td>\n",
       "      <td>Directed by B.S. Johnson.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22341</th>\n",
       "      <td>69353</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finnish soft erotic movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33370</th>\n",
       "      <td>171759</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sequel to Pitch Perfect 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43789</th>\n",
       "      <td>55505</td>\n",
       "      <td>[{'id': 779, 'name': 'martial arts'}, {'id': 7...</td>\n",
       "      <td>[martial arts, kung fu, drug, kickboxing]</td>\n",
       "      <td>[{'id': 779, 'name': 'martial arts'}, {'id': 7...</td>\n",
       "      <td>Scandal: Sex@students.edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18328</th>\n",
       "      <td>293114</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A film by Juho Kuosmanen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42213</th>\n",
       "      <td>393158</td>\n",
       "      <td>[{'id': 1930, 'name': 'kidnapping'}, {'id': 10...</td>\n",
       "      <td>[kidnapping, disappearance, woman director]</td>\n",
       "      <td>[{'id': 1930, 'name': 'kidnapping'}, {'id': 10...</td>\n",
       "      <td>Directed by Vasilis Vafeas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33044</th>\n",
       "      <td>101420</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A young woman's bleak life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13513</th>\n",
       "      <td>143240</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Journey to find true love.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                           keywords  \\\n",
       "21818   91745  [{'id': 497, 'name': 'shakespeare'}, {'id': 13...   \n",
       "20301   84328                                                 []   \n",
       "35326  351819  [{'id': 572, 'name': 'sex'}, {'id': 9215, 'nam...   \n",
       "31468   87884  [{'id': 293, 'name': 'female nudity'}, {'id': ...   \n",
       "30334   13803  [{'id': 12663, 'name': 'little girl'}, {'id': ...   \n",
       "34664  337751  [{'id': 9073, 'name': 'marilyn monroe'}, {'id'...   \n",
       "43368  435351          [{'id': 9716, 'name': 'stand-up comedy'}]   \n",
       "22078   15991  [{'id': 293, 'name': 'female nudity'}, {'id': ...   \n",
       "27491  171292         [{'id': 174878, 'name': 'female vampire'}]   \n",
       "43931  255552  [{'id': 380, 'name': 'brother brother relation...   \n",
       "32513  270470  [{'id': 344, 'name': 'inquisition'}, {'id': 43...   \n",
       "13305  260528                                                 []   \n",
       "20760   85510  [{'id': 2106, 'name': 'cold war'}, {'id': 4210...   \n",
       "1632   279698                                                 []   \n",
       "43086  424661  [{'id': 1530, 'name': 'temple'}, {'id': 10364,...   \n",
       "22180   54236  [{'id': 9935, 'name': 'travel'}, {'id': 155733...   \n",
       "31475  337879                                                 []   \n",
       "40187  377462  [{'id': 41385, 'name': 'racial tension'}, {'id...   \n",
       "13313  125705               [{'id': 497, 'name': 'shakespeare'}]   \n",
       "38682  356326  [{'id': 12377, 'name': 'zombie'}, {'id': 18895...   \n",
       "35692  376358                                                 []   \n",
       "40186  305309         [{'id': 187056, 'name': 'woman director'}]   \n",
       "39471   46740           [{'id': 161817, 'name': 'monty python'}]   \n",
       "22341   69353                                                 []   \n",
       "33370  171759                                                 []   \n",
       "43789   55505  [{'id': 779, 'name': 'martial arts'}, {'id': 7...   \n",
       "18328  293114                                                 []   \n",
       "42213  393158  [{'id': 1930, 'name': 'kidnapping'}, {'id': 10...   \n",
       "33044  101420                                                 []   \n",
       "13513  143240                                                 []   \n",
       "\n",
       "                                           keywords_list  \\\n",
       "21818  [shakespeare, teenager, middle ages, family fe...   \n",
       "20301                                                NaN   \n",
       "35326           [sex, black, parody, spoof, millionaire]   \n",
       "31468                           [female nudity, teacher]   \n",
       "30334                              [little girl, killer]   \n",
       "34664                   [marilyn monroe, woman director]   \n",
       "43368                                  [stand-up comedy]   \n",
       "22078                            [female nudity, orgasm]   \n",
       "27491                                   [female vampire]   \n",
       "43931  [brother brother relationship, family, missing...   \n",
       "32513   [inquisition, painter, spain, artist, biography]   \n",
       "13305                                                NaN   \n",
       "20760                     [cold war, panic, nuclear war]   \n",
       "1632                                                 NaN   \n",
       "43086                          [temple, mission, jungle]   \n",
       "22180                       [travel, old house, segovia]   \n",
       "31475                                                NaN   \n",
       "40187  [racial tension, american football player, mur...   \n",
       "13313                                      [shakespeare]   \n",
       "38682                                    [zombie, virus]   \n",
       "35692                                                NaN   \n",
       "40186                                   [woman director]   \n",
       "39471                                     [monty python]   \n",
       "22341                                                NaN   \n",
       "33370                                                NaN   \n",
       "43789          [martial arts, kung fu, drug, kickboxing]   \n",
       "18328                                                NaN   \n",
       "42213        [kidnapping, disappearance, woman director]   \n",
       "33044                                                NaN   \n",
       "13513                                                NaN   \n",
       "\n",
       "                                            keywords_nan  \\\n",
       "21818  [{'id': 497, 'name': 'shakespeare'}, {'id': 13...   \n",
       "20301                                                NaN   \n",
       "35326  [{'id': 572, 'name': 'sex'}, {'id': 9215, 'nam...   \n",
       "31468  [{'id': 293, 'name': 'female nudity'}, {'id': ...   \n",
       "30334  [{'id': 12663, 'name': 'little girl'}, {'id': ...   \n",
       "34664  [{'id': 9073, 'name': 'marilyn monroe'}, {'id'...   \n",
       "43368          [{'id': 9716, 'name': 'stand-up comedy'}]   \n",
       "22078  [{'id': 293, 'name': 'female nudity'}, {'id': ...   \n",
       "27491         [{'id': 174878, 'name': 'female vampire'}]   \n",
       "43931  [{'id': 380, 'name': 'brother brother relation...   \n",
       "32513  [{'id': 344, 'name': 'inquisition'}, {'id': 43...   \n",
       "13305                                                NaN   \n",
       "20760  [{'id': 2106, 'name': 'cold war'}, {'id': 4210...   \n",
       "1632                                                 NaN   \n",
       "43086  [{'id': 1530, 'name': 'temple'}, {'id': 10364,...   \n",
       "22180  [{'id': 9935, 'name': 'travel'}, {'id': 155733...   \n",
       "31475                                                NaN   \n",
       "40187  [{'id': 41385, 'name': 'racial tension'}, {'id...   \n",
       "13313               [{'id': 497, 'name': 'shakespeare'}]   \n",
       "38682  [{'id': 12377, 'name': 'zombie'}, {'id': 18895...   \n",
       "35692                                                NaN   \n",
       "40186         [{'id': 187056, 'name': 'woman director'}]   \n",
       "39471           [{'id': 161817, 'name': 'monty python'}]   \n",
       "22341                                                NaN   \n",
       "33370                                                NaN   \n",
       "43789  [{'id': 779, 'name': 'martial arts'}, {'id': 7...   \n",
       "18328                                                NaN   \n",
       "42213  [{'id': 1930, 'name': 'kidnapping'}, {'id': 10...   \n",
       "33044                                                NaN   \n",
       "13513                                                NaN   \n",
       "\n",
       "                             tmpp  \n",
       "21818        Film by Risto Jarva.  \n",
       "20301        American Documentary  \n",
       "35326        Finnish documentary.  \n",
       "31468        Based on true events  \n",
       "30334       For a Book of Dollars  \n",
       "34664       Standup in Las Vegas.  \n",
       "43368       A journey into night.  \n",
       "22078      A film by Jari Halonen  \n",
       "27491      A man dances on curbs.  \n",
       "43931      Love on the front page  \n",
       "32513      Movie by Luciano Salce  \n",
       "13305     Frisian movie from 2004  \n",
       "20760     Film by Veikko Aaltonen  \n",
       "1632      Film from Stephen Kijak  \n",
       "43086     English gangster flick.  \n",
       "22180     Short WW II documentary  \n",
       "31475    Directed by Vanessa Hope  \n",
       "40187    Fifth Break Blade Movie.  \n",
       "13313    To be or not to be, etc.  \n",
       "38682    Thrice upon a love story  \n",
       "35692   Directed by  Özcan Deniz.  \n",
       "40186   Fourth Break Blade Movie.  \n",
       "39471   Directed by B.S. Johnson.  \n",
       "22341   Finnish soft erotic movie  \n",
       "33370   Sequel to Pitch Perfect 2  \n",
       "43789   Scandal: Sex@students.edu  \n",
       "18328   A film by Juho Kuosmanen.  \n",
       "42213  Directed by Vasilis Vafeas  \n",
       "33044  A young woman's bleak life  \n",
       "13513  Journey to find true love.  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values(by=\"tmpp\", key=lambda x: x.str.len()).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a775c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fbb3a20",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from en-core-web-md==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.61.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: jinja2 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: setuptools in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (49.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.26.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.8.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.18.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (21.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "#!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4b132f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6bdb4b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_POS = set(['VERB', 'NOUN', 'ADJ', 'PROPN'])\n",
    "specific_stw = set(['relevant', 'simple', 'base'])\n",
    "\n",
    "def text_preprocessing(rawtext):\n",
    "    #Sentence tokenization and filtering of non-English sentences\n",
    "    #mult_doc = mult_nlp(rawtext)\n",
    "    #english_text = ' '.join([sent.text for sent in mult_doc.sents if sent._.language['language']=='en'])\n",
    "\n",
    "    #Tokenization\n",
    "    english_doc = nlp(rawtext)\n",
    "\n",
    "    new_tokens = list()\n",
    "\n",
    "    for token in english_doc:\n",
    "        # POS\n",
    "        if token.pos_ not in valid_POS:\n",
    "            continue\n",
    "        \n",
    "        # alphanumeric\n",
    "        if not token.is_alpha:\n",
    "            continue\n",
    "\n",
    "        # stopwords\n",
    "        if token.is_stop or token.text in specific_stw:\n",
    "            continue\n",
    "\n",
    "        new_tokens.append(token)\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatized_text = ' '.join([token.lemma_ for token in new_tokens])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "90432c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data[\"preprocessed_overview\"] = full_data[\"overview_filtered\"].apply(lambda x: text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c4ff3895",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [row['preprocessed_overview'].split() for idx, row in full_data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "92808c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create dictionary of tokens\n",
    "D = Dictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "57f11a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Review (lemmas) =============\n",
      "Pennsylvania band score hit ride star make machinery lot help manager\n",
      "\n",
      "============= Sparse vector representation =============\n",
      "[(299, 1), (633, 1), (1022, 1), (1031, 1), (1053, 1), (1451, 1), (1452, 1), (2335, 1), (3171, 1), (5937, 1), (7998, 1)]\n",
      "\n",
      "============= Word counts for the review =============\n",
      "[('star', 1), ('help', 1), ('band', 1), ('hit', 1), ('make', 1), ('lot', 1), ('manager', 1), ('ride', 1), ('Pennsylvania', 1), ('score', 1), ('machinery', 1)]\n"
     ]
    }
   ],
   "source": [
    "reviews_bow = [D.doc2bow(doc) for doc in corpus]\n",
    "\n",
    "n_review = 1000\n",
    "print('============= Review (lemmas) =============')\n",
    "print(' '.join(corpus[n_review]))\n",
    "\n",
    "print('\\n============= Sparse vector representation =============')\n",
    "print(reviews_bow[n_review])\n",
    "\n",
    "print('\\n============= Word counts for the review =============')\n",
    "print(list(map(lambda x: (D[x[0]], x[1]), reviews_bow[n_review])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "554e376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel\n",
    "\n",
    "tfidf = TfidfModel(reviews_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0a3ff749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= TFIDF representation for the project =============\n",
      "[(299, 0.195012524874713), (633, 0.16796274707208164), (1022, 0.25016603620399097), (1031, 0.2500826419276045), (1053, 0.20458547875315558), (1451, 0.2895699753904568), (1452, 0.3041608918825714), (2335, 0.28024346803581934), (3171, 0.41318113138755014), (5937, 0.33150713897989326), (7998, 0.480897482269683)]\n",
      "\n",
      "============= TFIDF applying the transformation only to the document =============\n",
      "[(299, 0.195012524874713), (633, 0.16796274707208164), (1022, 0.25016603620399097), (1031, 0.2500826419276045), (1053, 0.20458547875315558), (1451, 0.2895699753904568), (1452, 0.3041608918825714), (2335, 0.28024346803581934), (3171, 0.41318113138755014), (5937, 0.33150713897989326), (7998, 0.480897482269683)]\n"
     ]
    }
   ],
   "source": [
    "reviews_tfidf = tfidf[reviews_bow]\n",
    "n_project = 1000\n",
    "print('============= TFIDF representation for the project =============')\n",
    "print(reviews_tfidf[n_review])\n",
    "\n",
    "print('\\n============= TFIDF applying the transformation only to the document =============')\n",
    "print(tfidf[reviews_bow[n_review]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4b9ba3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x15a6b4670>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "432a037a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        lead Woody Andy toy live room Andy birthday br...\n",
       "1        sibling Judy Peter discover enchanted board ga...\n",
       "2        family wedding reignite ancient feud door neig...\n",
       "3        cheat mistreat step woman hold breath wait elu...\n",
       "4        George Banks recover daughter wedding receive ...\n",
       "                               ...                        \n",
       "45291                                  rise fall man woman\n",
       "45292    artist struggle finish work storyline cult pla...\n",
       "45293    hit go wrong professional assassin end suitcas...\n",
       "45294    small town live brother minister hunchback pai...\n",
       "45295    year decriminalisation homosexuality UK direct...\n",
       "Name: preprocessed_overview, Length: 45296, dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data[\"preprocessed_overview\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5f8aacc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jealousy toy boy friendship friends rivalry boy next door new toy toy comes to life'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(full_data.iloc[0][\"keywords_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a05cc3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data[\"keywords_list\"] = full_data[\"keywords_list\"].apply(lambda x: \" \".join(x) if x is not np.nan else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "91278d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data[\"preprocessed_keywords\"] = full_data[\"keywords_list\"].apply(lambda x: text_preprocessing(x) if x is not np.nan else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1e857c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        jealousy toy boy friendship friend rivalry boy...\n",
       "1        board game disappearance new home recluse gian...\n",
       "2            fish good friend duringcreditsstinger old man\n",
       "3        base novel interracial relationship single mot...\n",
       "4        baby midlife crisis confidence age daughter mo...\n",
       "                               ...                        \n",
       "45291                                          tragic love\n",
       "45292                                    artist play pinoy\n",
       "45293                                                  NaN\n",
       "45294                                                  NaN\n",
       "45295                                                  NaN\n",
       "Name: preprocessed_keywords, Length: 45296, dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data[\"preprocessed_keywords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3075120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data[\"overview_plus_keyword_preprocessed\"] = full_data[\"preprocessed_overview\"] + full_data[\"preprocessed_keywords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4dbb6a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature and target dataframes\n",
    "X = full_data[[\"preprocessed_overview\"]]\n",
    "y = full_data[\"vote_average\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "44adf61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, \n",
    "                                                    random_state = 21, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4a64f481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35228</th>\n",
       "      <td>year old cycling talent Freddy son butcher idy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13737</th>\n",
       "      <td>overweight loner Rino spend day seclusion dad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34687</th>\n",
       "      <td>Raggedy Ann Andy leave playroom rescue Babette...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30067</th>\n",
       "      <td>Zenon Kar teenager live space station year com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32779</th>\n",
       "      <td>orphan young age Scriptwriter Amit military pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16432</th>\n",
       "      <td>Caitlin Fairchild teenager offer place institu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8964</th>\n",
       "      <td>busload woman strand isolated canadian country...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5944</th>\n",
       "      <td>Monty Python live Hollywood Bowl concert film ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5327</th>\n",
       "      <td>beautiful sophisticated woman Oscar Grubman se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15305</th>\n",
       "      <td>Architect Paul Thomas insinuate relationship b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31707 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   preprocessed_overview\n",
       "35228  year old cycling talent Freddy son butcher idy...\n",
       "13737  overweight loner Rino spend day seclusion dad ...\n",
       "34687  Raggedy Ann Andy leave playroom rescue Babette...\n",
       "30067  Zenon Kar teenager live space station year com...\n",
       "32779  orphan young age Scriptwriter Amit military pi...\n",
       "...                                                  ...\n",
       "16432  Caitlin Fairchild teenager offer place institu...\n",
       "8964   busload woman strand isolated canadian country...\n",
       "5944   Monty Python live Hollywood Bowl concert film ...\n",
       "5327   beautiful sophisticated woman Oscar Grubman se...\n",
       "15305  Architect Paul Thomas insinuate relationship b...\n",
       "\n",
       "[31707 rows x 1 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ce44ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence \n",
    "\n",
    "# sequence words\n",
    "# X_train_seq is a list with each element being a list of each word in one article as a separate string\n",
    "\n",
    "X_train_seq = [text_to_word_sequence(zz) for zz in X_train[\"preprocessed_overview\"]]\n",
    "X_test_seq = [text_to_word_sequence(zz) for zz in X_test[\"preprocessed_overview\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "52231e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f31928d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolas/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/gensim/models/doc2vec.py:319: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, corpus_file, dm_mean, dm, dbow_words, dm_concat, dm_tag_count, docvecs, docvecs_mapfile, comment, trim_rule, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You can't pass a generator as the documents argument. Try a sequence.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             self.train(\n\u001b[1;32m    361\u001b[0m                 \u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, documents, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \"\"\"\n\u001b[0;32m--> 926\u001b[0;31m         total_words, corpus_count = self.vocabulary.scan_vocab(\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocvecs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0mprogress_per\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, documents, corpus_file, docvecs, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTaggedLineDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m         \u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scan_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         logger.info(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36m_scan_vocab\u001b[0;34m(self, documents, docvecs, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdocument_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchecked_string_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m                     logger.warning(\n\u001b[1;32m   1056\u001b[0m                         \u001b[0;34m\"Each 'words' should be a list of words (usually unicode strings). \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# dimensions of vector embedding\n",
    "dim_embedding = 100\n",
    "\n",
    "# create Word2Vec on Train set\n",
    "d2v = Doc2Vec(sentences = X_train_seq, size = dim_embedding, window = 5, min_count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6cd07c0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd2v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/34/1yvhb8vj085g3m5tpn1x91d80000gn/T/ipykernel_72364/2985988131.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md2v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'd2v' is not defined"
     ]
    }
   ],
   "source": [
    "d2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cbec8777",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd2v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/34/1yvhb8vj085g3m5tpn1x91d80000gn/T/ipykernel_72364/3236801142.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"thriller\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'd2v' is not defined"
     ]
    }
   ],
   "source": [
    "d2v.wv.most_similar(\"thriller\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
